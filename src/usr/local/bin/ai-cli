#!/bin/bash
#    AI-CLI Simplifying AI Experiments
#    Copyright (C) 2022  Marcel Arpogaus, Julian Jandeleit
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <https://www.gnu.org/licenses/>.

# Exit on Error
set -e

# Function definitions #########################################################
show_help() {
	DSC_PATTERN="[[:alnum:][:blank:]_\.\(\)\$\-\,\'<>]"
	DOC_PATTERN="#[[:blank:]]*($DSC_PATTERN*(@[A-Z]{3,}@?)?$DSC_PATTERN*)"
	OPTIONS_PATTERN="^[[:blank:]]*([a-z])\)[[:blank:]]*${DOC_PATTERN}$"
	OPTIONS=$(grep -P "$OPTIONS_PATTERN" "$0")
	COMMANDS_PATTERN="^[[:blank:]]*([a-z\-]{3,})\)[[:blank:]]*${DOC_PATTERN}$"
	COMMANDS=$(grep -P "$COMMANDS_PATTERN" "$0")
	spaces=$(printf ' %.0s' {1..100})
	echo "Usage: $(basename "$0") [OPTIONS] COMMAND [ARGS...]"
	echo ""
	echo "This script helps you to conduct your ai experiments."
	echo ""
	echo "Options:"
	IFS=$'
'
	for o in $OPTIONS 'h)#Show help'; do
		[[ $o =~ $OPTIONS_PATTERN ]]
		opt=${BASH_REMATCH[1]}
		arg=$(tr -d @ <<<${BASH_REMATCH[3]})
		desc=$(export GPUS CUDA_VERSION; tr -d @ <<<${BASH_REMATCH[2]} | envsubst)
		d="$((18 - ${#cmd} - ${#arg}))"
		printf "  -%s %s%0.*s%s
" "$opt" "$arg" $d $spaces "$desc"
	done
	echo ""
	echo "Commands:"
	IFS=$'
'
	for c in $COMMANDS; do
		[[ $c =~ $COMMANDS_PATTERN ]]
		cmd=${BASH_REMATCH[1]}
		arg=$(tr -d @ <<<${BASH_REMATCH[3]})
		desc=$(tr -d @ <<<${BASH_REMATCH[2]})
		d="$((20 - ${#cmd} - ${#arg}))"
		printf "  %s %s%0.*s%s
" "$cmd" "$arg" $d $spaces "$desc"
	done
}

dc(){
	set -x
	FILE=$1
	shift
	docker-compose --project-name $USER-$FILE \
		--file "${DOCKER_COMPOSE_PATH}/${FILE}.docker-compose.yaml" \
		$*
	set +x
}

docker_run(){
	SERVICE_NAME=$1
	shift
	dc workspace --project-directory "$PWD" \
		run $RUN_ARGS \
		$SERVICE_NAME "$*"
}

basic_auth(){
	echo "INFO:     basic_auth ${HTPASSWD_PATH} -- $1"
	ls ${HTPASSWD_PATH}
	# Create htpasswd for Basic Auth
	if [[ ! -e ${HTPASSWD_PATH}/$1 ]]; then
		echo "Please enter a username and password to restrict access to: $1"
		# Read Username
		echo -n "Username: "
		read -r username
		[ -z $username ] && exit 1
		# Read Password
		echo -n "Password: "
		read -rs password
		[ -z $password  ] && exit 1
		echo

		htpasswd -Bb -c "${HTPASSWD_PATH}/$1" $username $password

	fi
}
init(){
	echo "INFO: Initialization started"
	echo "INFO: init ${USER}_mlflow_bridge"
	docker network create ${USER}_mlflow_bridge &> /dev/null || true # to continue if already exists
	echo "INFO: init ${HOME_PATH}"
	mkdir -p ${HOME_PATH}
	cp -r "${CONFIG_FILES_PATH}/.condarc" "${HOME_PATH}"
	cp    "${CONFIG_FILES_PATH}/.bashrc" "${HOME_PATH}"
	mkdir -p $EXTENSION_PATH
	chmod 777 $EXTENSION_PATH
	echo "INFO: init docker workspace"
	ai-cli build &> /dev/null
	docker_run workspace mamba create --yes -n ai-cli &> /dev/null 
	echo "INFO: init mlflow server"
	ai-cli build-server &> /dev/null
	echo "INFO: Initialization complete"	
}
check_init(){
	err_cnt=0	
	# check dependencies that can be set up using init()
	if	[[ -n $(docker network inspect $(docker network ls -q) | grep "${USER}_mlflow_bridge") ]] &&
		[[ -w "${HOME_PATH}" ]] ; then
		: # null command
	else
		echo ""
		echo "################################################################"
		echo ""
		echo "ERROR:    Incomplete initialization!"
		echo "          Please run 'ai-cli init'."
		echo ""
		echo "################################################################"
		echo ""

		((err_cnt+=1))
	fi

	# check for dependencies that currently need to be set up manually
	if [[ ! -n $(git config user.name) ]] ||
	   [[ ! -n $(git config user.email) ]] ; then
		echo ""
		echo "################################################################"
		echo ""
		echo "ERROR:    Git user not found!"
		echo "          Please setup global git user:"
		echo "          'git config --global user.name [YOUR USER NAME]'"
		echo "          'git config --global user.email [YOUR EMAIL]'"
		echo ""
		echo "################################################################"
		echo ""

		((err_cnt+=1))
	fi

	return ${err_cnt}
}
disambiguate_host(){	
	### relies on "notebook" and "lab" being present in url ###

	# check if hosts are already in use
	hname=$1
	instances=""
	if [ -n "$JUPYTER_CONTAINER" ]; then
		hosts=$( echo "$JUPYTER_CONTAINER" | xargs docker inspect -f '                
		{{range .Config.Env }}
                        {{with $line := (split . "=")}}
                                {{if eq (index . 0) "VIRTUAL_HOST"}}
                                        {{ index . 1 }}
                                {{end}}
                        {{end}}
                {{end}}
		')
		# instances from same user with same name
		# cat is needed to prevent exit on negative result
		# note that expected format is hardcoded here
		hname_front=$(echo "$hname" | sed -E "s/(^[A-Za-z]+\-[A-Za-z]+).*/\1/" | cat)	
		instances=$(echo "$hosts" | grep "$hname_front")
		# numbers alreaady occupied
		numbers=$(echo "$instances" | sed -E "s/.*([0-9])\..*/\1/")
	fi
	# no running instance, no need to calculate number to append
	if [ "$instances" = "" ]; then
		echo "$hname"
		return 0
	fi

	n_max=10
	changed=0
	for i in $(seq 2 $n_max)
	do
		found=$(echo "$numbers" | grep -c "$i" | cat)
		#echo "i=$i: $found"
		# number not in use, so can be used here
		if [ "$found" -eq "0" ]; then
			hname=$(echo "$hname" | sed -E "s/(\-lab|\-notebook)/\1\-${i}/")
			changed=1
			break	
		fi
	done
	
	# Error if something should have changed but didn't  due to maximum number reached.
	if [ "$changed" -eq "0" ]; then
		echo "ERROR: Too many open jupyter instances. Instances of same type may not exceed $n_max."
		exit 1
	fi

	echo "$hname"
}

# ---- show related functions
show_docker_associated_images()
{
	echo "Docker Associated Images"
	docker image list "${IMAGE_PREFIX}" | \
	while read -r line
	do
		  printf '   %s\n' "$line"
	done
}
show_jupyter_status(){
	if [ -n "$JUPYTER_CONTAINER" ]; then
		# we use go templates to build the desired output
		# numbers below are arbitrary max-width borders used to align columns
		echo "Jupyter Server"
		jupyter_sourcepaths=$( echo "$JUPYTER_CONTAINER" | xargs docker container inspect -f '	
		{{range .Mounts}}
			{{if eq .Destination "/app"}}
				{{.Source}}
			{{end}}
		{{end}}
		')
		jupyter_urls=$( echo "$JUPYTER_CONTAINER" | xargs docker container inspect -f '	
		{{range .Config.Env }}
			{{with $line := (split . "=")}}
				{{if eq (index . 0) "VIRTUAL_HOST"}}
					{{ index . 1 }}
				{{end}}
			{{end}}
		{{end}}
		')
		jupyter_cudas=$( echo "$JUPYTER_CONTAINER" | xargs docker container inspect -f '	
		{{ $found := "False" }}
		{{range .Config.Env}}	
			{{with $line := (split . "=")}}
				{{if eq (index . 0) "CUDA_VERSION"}}
					{{index . 1}}
					{{ $found = "True" }}
				{{end}}
			{{end}}
		{{end}}
		{{ if eq $found "False"  }}
		   None
		{{end}}
		')
		
		# convert to arrays to be able to index lists
		jupyter_sourcepaths=($(echo $jupyter_sourcepaths))
		jupyter_urls=($(echo $jupyter_urls))
		jupyter_cudas=($(echo $jupyter_cudas))
		otheruserjups=0
		# print aligned
		printf "   %*s %*s %*s
" -50 "JUPYTER URL" -50 "(JUPYTER WORKSPACE)" -50 "(RUNNING CUDA)"

		for ((i=0; i < ${#jupyter_urls[@]}; ++i))
		do
			# check user by looking if url _starts_ with user
			if [[ ! "${jupyter_urls[$i]}" == "$USER"* ]]; then
				otheruserjups=$((otheruserjups+1))
			else
				# numbers are for aligned formatting (may be needed to be improved in future)
				printf "   %*s %*s %*s
" -50 "https://${jupyter_urls[$i]}" -50 "(${jupyter_sourcepaths[$i]})" -50 "(CUDA ${jupyter_cudas[$i]})"
			fi
		done
		echo ""
		echo "   There are $otheruserjups instances running from other users."
	else
		echo " No jupyter server running"
	fi
}
show_mlflow_status(){
	
	echo "MLflow Information"

	if [ $(docker ps -qf name=${USER}-mlflow-server) ]; then
		echo "   https://${MLFLOW_VIRTUAL_HOST}"
	else
		echo "   MLFLOW inactive"
	fi

}
show_status(){
	
	show_docker_associated_images
	echo ""
	show_mlflow_status
	echo ""
	show_jupyter_status
}


# Define Paths on HOST system #################################################################
DOCKER_COMPOSE_PATH=/usr/local/share/ai-cli-docker/
HTPASSWD_PATH=/usr/share/ai-cli/htpasswd
HOME_PATH="/home/${USER}/.local/share/ai-cli/home"
EXTENSION_PATH="/home/${USER}/.local/share/ai-cli/extensions"
MLFLOW_DATA=/mnt/data/$USER/mlflow
CONFIG_PATH=/etc/ai-cli/config
CONFIG_FILES_PATH=/etc/ai-cli/files

# Check if config path exists
[[ ! -e $DOCKER_COMPOSE_PATH ]] && {
	echo "ERROR: Required files not found!"
	echo "       Check your installation"
	exit 1
}

# Variable definitions #########################################################
# read in configuration file
source $CONFIG_PATH

# define other helper variables
MLFLOW_LOCAL_PROJECT="$PWD"
DOCKER_USER=$(id -u):$(id -g)
NB_UID=$(id -u)
NB_GID=$(id -g)
GIT_USER_NAME="'$(git config --get user.name)'" # git used in workspace-base/entrypoint.sh
GIT_USER_EMAIL="$(git config --get user.email)"
MLFLOW_VIRTUAL_HOST=${USER}-mlflow.$URLNAME
JUPYTER_CMD="jupyter notebook --notebook-dir=/app --ip 0.0.0.0 --no-browser"
JUPYTER_LAB_CMD="jupyter lab --notebook-dir=/app --ip 0.0.0.0 --no-browser --collaborative"
JUPYTER_CONTAINER=$(docker ps -qf name=".*jupyter.*")
NOTEBOOK_VIRTUAL_HOST=${USER}-notebook.$URLNAME
LAB_VIRTUAL_HOST=${USER}-lab.$URLNAME

# default runtime
# read from docker and extract value
RUNTIME=$(docker info | grep -i "Default Runtime")
RUNTIME=${RUNTIME#*: }

# define image repo prefix and tag
IMAGE_TAG="default"
IMAGE_PREFIX=ai-cli/${USER}

# CLI args defaults
GPUS=""
RUN_VOLUMES=()
RUN_ARGS="--rm"
CONDA_DIR="/home/${USER}/.conda/envs/"

# CHECK INIT ###################################################################
# Looks at known dependencies and errors if it finds at least one of them unmet.
# The init method fixes issues that can be solved automatically. This is necessary
# setup user workspace before first use.
[ "$1" = init ] || check_init || {
	exit $v
}

# CLI Arguments ################################################################
while getopts :he:g:n:c:v:i:t:r: flag
do
	case "${flag}" in
		v)  # Specify additional docker @VOLUME@s
			# -v is only valid on certain commands
			valid_commands=("bash run lab notebook")
			valid_v=false
			for token in "$@"; do
				if [[ " ${valid_commands[*]} " =~ " ${token} " ]]; then
					valid_v=true
				fi
			done
			if [[ $valid_v = false ]]; then
				echo "ERROR: -v used in wrong context. Only valid when command is in list: ${valid_commands}."
				exit 1
			fi


			RUN_VOLUMES+=($OPTARG);;
		e)  # Specify environment @FILE
			MLFLOW_ENV_FILE=${OPTARG} && source "$MLFLOW_ENV_FILE";;
		g)  # Enable gpu support. Set specific @GPUS, e.g. 0,1 for gpu 0 and 1.
			GPUS=${OPTARG}
			RUNTIME="nvidia";;	
		r) # Specify specific @RUNTIME. Default is read from docker info.
			RUNTIME=${OPTARG};; # needs to be placed after g flag to work
		n)  # Specify experiment @NAME
			MLFLOW_EXPERIMENT_NAME=${OPTARG};;
		c) # Build with cuda support. Specify @CUDA version to use. Tags image with 'c<VERSION>' by default.
			valid_c=false
			for token in "$@"; do
				if [[ $token = "build" ]]; then
					valid_c=true
				fi
			done
			if [[ $valid_c = false ]]; then
				echo "ERROR: -c used in wrong context. Only valid when you call 'build'."
				exit 1
			fi
			CUDA_VERSION=${OPTARG}
			IMAGE_TAG=c"$CUDA_VERSION"

			;;	
			
		i) # Specify docker @IMAGE to be used.
			valid_i=true
			for token in "$@"; do
				if [[ $token = "build" ]]; then
					valid_i=false
				fi
			done
			if [[ $valid_i = false ]]; then
				echo "ERROR: -i used in wrong context. Not valid when you call 'build' use -t or -c instead."
				exit 1
			fi
			IMAGE_NAME="${OPTARG}"
		;;

		t) # Specify image @TAG to be used.
			IMAGE_TAG="${OPTARG}"
		;;
		*) show_help && exit 0;;
	esac
done
shift $((OPTIND-1)) # to skip option arguments when evaulating command

# CLI args for docker-compose run
for v in ${RUN_VOLUMES[@]}; do
	RUN_ARGS+=" -v $v"
done
if [[ -n $MLFLOW_EXPERIMENT_NAME  ]]; then
	RUN_ARGS+=" -e MLFLOW_EXPERIMENT_NAME=$MLFLOW_EXPERIMENT_NAME"
fi

# BUILD IMAGE NAME TO USE
if [[ -z "$IMAGE_NAME" ]]; then
	IMAGE_NAME=${IMAGE_PREFIX}:${IMAGE_TAG};
fi

# Exports #####################################################################
# Export env for docker-compose
if [[ -e $MLFLOW_ENV_FILE ]]; then
	export MLFLOW_ENV_FILE
fi

export MLFLOWPORT
export JUPYTERPORT
export URLNAME
export MLFLOW_DATA
export DOCKER_USER
export NB_UID
export NB_GID
export GIT_USER_NAME
export GIT_USER_EMAIL
export IMAGE_NAME
export EXTENSION_PATH
export RUNTIME
export GPUS
export MLFLOW_VERSION
export CONDA_DIR

#echo "INFO: MLFLOW_VERSION=${MLFLOW_VERSION}"
#echo "INFO: DOCKER_USER=${DOCKER_USER}"
#echo "INFO: MLFLOW_DATA=${MLFLOW_DATA}"
#echo "INFO: URLNAME=${URLNAME}"
#echo "INFO: MLFLOWPORT=${MLFLOWPORT}"

# show docker info ####################################################################
echo "INFO: Using image ${IMAGE_NAME}"
echo "INFO: using runtime $RUNTIME"
echo "INFO: using gpus '$GPUS'"
# Run command ##################################################################
if [[ $# == 0 ]]; then
	show_help && exit 1
else
	CMD=$1
	shift
fi
case ${CMD} in
	init) # initialize this script for your user
		init;;
	start-server) # start mlflow server
		basic_auth "$MLFLOW_VIRTUAL_HOST"
		dc server up -d ;;
	stop-server) # stop mlflow server
		dc server down ;;
	restart-server) # restart mlflow server
		dc server down
		ai-cli build-server
		dc server up -d;;
	build-server) # build mlflow server
		dc server build --build-arg=MLFLOW_VERSION=$MLFLOW_VERSION
		;;
	status) # show status of your environment
		show_status ;;
	build) # build image from dockerfile
		
		# workspace-cuda depends on workspace-base image existing so is always built
		echo "INFO: Specified Cuda Version: '${CUDA_VERSION}'"
		echo "INFO: Building workspace-base"
		docker build \
			-t ${IMAGE_NAME} \
			-t ai-cli/workspace-base \
			--build-arg=ARG_NB_USER="$USER" \
			--build-arg=ARG_NB_UID="$NB_UID" \
			--build-arg=ARG_NB_GID="$NB_GID" \
			--build-arg=ARG_HOME="/home/${USER}" \
			--build-arg=MLFLOW_VERSION="$MLFLOW_VERSION" \
		       	/usr/local/share/ai-cli-docker/workspace-base/
		
		if [ ${CUDA_VERSION} ]; then 
		echo "INFO: Building workspace-cuda"; 
		# version formats vary so we need to split into major and minor version
		CMAJ=${CUDA_VERSION%\.*}
		CMIN=${CUDA_VERSION#*\.}
		echo "INFO: CMAJ ${CMAJ}, CMIN ${CMIN}"
		echo "INFO: NVIDIA DRIVER ${DRIVER_VERSION}"
		docker build \
			-t ${IMAGE_NAME} \
			-t ai-cli/workspace-cuda:"$IMAGE_TAG" \
			--build-arg=CMAJ="$CMAJ" \
			--build-arg=CMIN="$CMIN" \
			/usr/local/share/ai-cli-docker/workspace-cuda/
		fi
		;;
	bash) # start bash shell inside container
		export MLFLOW_LOCAL_PROJECT
		docker_run workspace bash ;;
	notebook) # start jupyter notebook server
		JUPYTER_VIRTUAL_HOST=$(disambiguate_host $NOTEBOOK_VIRTUAL_HOST)
		export JUPYTER_VIRTUAL_HOST
		export MLFLOW_LOCAL_PROJECT
		echo "INFO: Running notebook server in: $MLFLOW_LOCAL_PROJECT"
		echo "      Listening at: https://$JUPYTER_VIRTUAL_HOST"
		docker_run jupyter $JUPYTER_CMD ;;
	lab) # start jupyter lab server	
		JUPYTER_VIRTUAL_HOST=$(disambiguate_host $LAB_VIRTUAL_HOST)
		export JUPYTER_VIRTUAL_HOST
		export MLFLOW_LOCAL_PROJECT
		echo "INFO: Running lab server in: $MLFLOW_LOCAL_PROJECT"
		echo "      Listening at: https://$JUPYTER_VIRTUAL_HOST"
		docker_run jupyter $JUPYTER_LAB_CMD;;
	exec) # execute @PROGRAMM inside container
		if [[ $# == 0 ]]; then
			echo "ERROR: Please provide a program name as argument"
			show_help
			exit 1
		fi
		export MLFLOW_LOCAL_PROJECT
		docker_run workspace $* ;;
	run) # run MLProject from @PATH inside container
		if [[ $# == 0 ]]; then
			echo "ERROR: Please provide a path as argument"
			show_help
			exit 1
		fi
		
		echo "INFO: MLFlow data path: $MLFLOW_DATA"
		if [[ -n $MLFLOW_EXPERIMENT_NAME  ]]; then
			echo "INFO: MLFlow experiment name: $MLFLOW_EXPERIMENT_NAME"
		fi
		export MLFLOW_LOCAL_PROJECT
		echo "INFO: Running MLProject from $MLFLOW_LOCAL_PROJECT"
		echo "INFO: Executed Command:  mlflow run $*"
		docker_run workspace mlflow run $* ;;
	run-from-git) # run MLProject from git repo at @URI inside container
		if [[ $# != 0 && -z $MLFLOW_GIT_PROJECT ]]; then
			MLFLOW_GIT_PROJECT=$1
		elif [[ $# == 0 && -z $MLFLOW_GIT_PROJECT ]]; then
			echo "ERROR: No git repo specified"
			show_help
			exit 1
		fi
		echo "INFO: Running MLProject from $MLFLOW_GIT_PROJECT" 
		docker_run workspace mlflow run $MLFLOW_GIT_PROJECT ;;
	reset-password) # Reset Password for mlflow you will setup a new one at next server start
		rm "${HTPASSWD_PATH}/${MLFLOW_VIRTUAL_HOST}"
		echo "successfully reset password"
		;;
	*) show_help && exit 1;;
esac
